{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_word_level_with_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihokwak/nlp/blob/master/seq2seq_word_level_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8eoKyZKjavW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDkc9RVkjcut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsIM79s-ju_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jku396xgjvCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or-I0nejjvFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "latent_dim = 50\n",
        "num_samples = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTOAPgQKlzXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "CUR_DIR = os.path.abspath(\".\")\n",
        "FILE_NAME = os.path.join(CUR_DIR, \"fra-eng.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QnzXy8yjvIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "resp = requests.get(\"https://raw.githubusercontent.com/jinfagang/pytorch_chatbot/master/datasets/eng-fra.txt\")\n",
        "with open(FILE_NAME, \"wb\") as f :\n",
        "  f.write(resp.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHtWq_llrUJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(FILE_NAME, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdpzdj5tlDIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = sorted(lines, key=len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egzdtDZYuHp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, line in enumerate(lines):\n",
        "    if len(line.split(\"\\t\")) < 2 :\n",
        "        continue\n",
        "    input_text, target_text = line.split(\"\\t\")[:2]\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8HCwVKauhee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = pd.DataFrame({'eng':input_texts, 'fra':target_texts})\n",
        "lines = lines[: min(num_samples, len(lines) - 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10hhAe1puktO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4d97d4c-5fb9-4858-c660-3fcbade17bb8"
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JIl0M1tuys7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Cleanup\n",
        "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
        "lines.fra=lines.fra.apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXSRRdk9u1Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take the length as 50\n",
        "import re\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
        "lines.fra=lines.fra.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PsdjneQu23Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines.fra=lines.fra.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuSS7EB7vCUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_digits = str.maketrans('', '', string.digits)\n",
        "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
        "lines.fra=lines.fra.apply(lambda x: x.translate(remove_digits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u4P8s_DvoHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate synthetic data\n",
        "lines.fra = lines.fra.apply(lambda x: 'START_ ' + x + ' _END')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUcr7SKevt4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create vocabulary of words\n",
        "all_eng_words = set()\n",
        "for eng in lines.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOLLDhB-v2Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_fra_words = set()\n",
        "for fra in lines.fra:\n",
        "    for word in fra.split():\n",
        "        if word not in all_fra_words:\n",
        "            all_fra_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiM8mmr0v9W2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a13f9a2b-ed73-4b9e-9f48-4eb72b0c28df"
      },
      "source": [
        "print(len(all_eng_words), len(all_fra_words))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2386 4545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv0I0IuhwC7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_encoder_seq_length = np.max([len(l.split()) for l in lines.eng])\n",
        "max_decoder_seq_length = np.max([len(l.split()) for l in lines.fra])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFKal5V7wa36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18b55f92-e7d3-4f76-de19-fe3145ab8212"
      },
      "source": [
        "print(max_encoder_seq_length,max_decoder_seq_length)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u9M2jrPwj2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_fra_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_fra_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLq9PN_nwo9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d6fbf42-284f-447c-cfca-35bf3882cb73"
      },
      "source": [
        "print(num_encoder_tokens,num_decoder_tokens)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2386 4545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Iqkvsrwt3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqqkK__w2eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros((len(lines.eng), max_encoder_seq_length),dtype='float32')\n",
        "decoder_input_data = np.zeros((len(lines.fra), max_decoder_seq_length),dtype='float32')\n",
        "decoder_target_data = np.zeros((len(lines.fra), max_decoder_seq_length, num_decoder_tokens), dtype=\"float16\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VTT9E_3w5h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.fra)):\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "        encoder_input_data[i, t] = input_token_index[word]\n",
        "    for t, word in enumerate(target_text.split()):\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTSST_WxpPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "en_x = layers.Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
        "encoder = layers.GRU(latent_dim, return_state=True)\n",
        "_, state_h = encoder(en_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mppL6jURxpVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "de_x = layers.Embedding(num_decoder_tokens, latent_dim)\n",
        "final_dex = de_x(decoder_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb1I7vZDxpYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder_gru(final_dex, initial_state=state_h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZUvlqnexpbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSP64rsYx9LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4-rfYzFyAyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "e8689b82-c127-4c51-d3c8-01efd3ddf986"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     119300      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 50)     227250      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     [(None, 50), (None,  15150       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gru_2 (GRU)                     [(None, None, 50), ( 15150       embedding_2[0][0]                \n",
            "                                                                 gru_1[0][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 4545)   231795      gru_2[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 608,645\n",
            "Trainable params: 608,645\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvh0Fa-_yCLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = os.path.abspath(\".\")\n",
        "WORK_DIR = \"seq2seq_keras\"\n",
        "os.makedirs(os.path.join(BASE_DIR, WORK_DIR), exist_ok=True)\n",
        "os.makedirs(os.path.join(BASE_DIR, WORK_DIR, \"model\"), exist_ok=True)\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath=os.path.join(BASE_DIR, WORK_DIR, \"model\", \"seq2seq2_gru_word_level_model.h5\"), monitor='loss', save_best_only=True)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxyBPhOkyLm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3733
        },
        "outputId": "910c7e6d-34c7-462a-89e1-97faf8573fb5"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "9000/9000 [==============================] - 23s 3ms/step - loss: 3.0626 - acc: 0.1232 - val_loss: 3.0276 - val_acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer gru_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'gru_1/while/Exit_2:0' shape=(?, 50) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 2.4665 - acc: 0.1394 - val_loss: 2.9629 - val_acc: 0.1394\n",
            "Epoch 3/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 2.3590 - acc: 0.1482 - val_loss: 2.9002 - val_acc: 0.1394\n",
            "Epoch 4/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 2.2442 - acc: 0.1492 - val_loss: 2.8037 - val_acc: 0.1422\n",
            "Epoch 5/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 2.1379 - acc: 0.1582 - val_loss: 2.7497 - val_acc: 0.1494\n",
            "Epoch 6/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 2.0505 - acc: 0.1686 - val_loss: 2.6822 - val_acc: 0.1638\n",
            "Epoch 7/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.9836 - acc: 0.1762 - val_loss: 2.6552 - val_acc: 0.1688\n",
            "Epoch 8/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.9304 - acc: 0.1819 - val_loss: 2.6179 - val_acc: 0.1766\n",
            "Epoch 9/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.8873 - acc: 0.1867 - val_loss: 2.5988 - val_acc: 0.1805\n",
            "Epoch 10/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.8515 - acc: 0.1919 - val_loss: 2.5695 - val_acc: 0.1891\n",
            "Epoch 11/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.8194 - acc: 0.1958 - val_loss: 2.5494 - val_acc: 0.1887\n",
            "Epoch 12/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.7909 - acc: 0.1980 - val_loss: 2.5251 - val_acc: 0.1910\n",
            "Epoch 13/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.7649 - acc: 0.2009 - val_loss: 2.5147 - val_acc: 0.1949\n",
            "Epoch 14/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.7404 - acc: 0.2033 - val_loss: 2.4984 - val_acc: 0.1960\n",
            "Epoch 15/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.7180 - acc: 0.2056 - val_loss: 2.4755 - val_acc: 0.1961\n",
            "Epoch 16/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.6973 - acc: 0.2077 - val_loss: 2.4577 - val_acc: 0.2023\n",
            "Epoch 17/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.6776 - acc: 0.2098 - val_loss: 2.4453 - val_acc: 0.2026\n",
            "Epoch 18/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.6591 - acc: 0.2110 - val_loss: 2.4339 - val_acc: 0.2049\n",
            "Epoch 19/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.6410 - acc: 0.2131 - val_loss: 2.4165 - val_acc: 0.2073\n",
            "Epoch 20/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.6241 - acc: 0.2147 - val_loss: 2.3980 - val_acc: 0.2088\n",
            "Epoch 21/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.6082 - acc: 0.2164 - val_loss: 2.3865 - val_acc: 0.2080\n",
            "Epoch 22/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.5928 - acc: 0.2174 - val_loss: 2.3777 - val_acc: 0.2092\n",
            "Epoch 23/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.5786 - acc: 0.2192 - val_loss: 2.3617 - val_acc: 0.2135\n",
            "Epoch 24/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.5636 - acc: 0.2208 - val_loss: 2.3615 - val_acc: 0.2124\n",
            "Epoch 25/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.5502 - acc: 0.2224 - val_loss: 2.3451 - val_acc: 0.2135\n",
            "Epoch 26/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.5368 - acc: 0.2231 - val_loss: 2.3343 - val_acc: 0.2165\n",
            "Epoch 27/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.5242 - acc: 0.2249 - val_loss: 2.3293 - val_acc: 0.2174\n",
            "Epoch 28/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.5112 - acc: 0.2259 - val_loss: 2.3261 - val_acc: 0.2166\n",
            "Epoch 29/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.4998 - acc: 0.2270 - val_loss: 2.3159 - val_acc: 0.2171\n",
            "Epoch 30/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.4878 - acc: 0.2279 - val_loss: 2.3042 - val_acc: 0.2195\n",
            "Epoch 31/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.4767 - acc: 0.2298 - val_loss: 2.3010 - val_acc: 0.2196\n",
            "Epoch 32/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.4656 - acc: 0.2308 - val_loss: 2.2966 - val_acc: 0.2194\n",
            "Epoch 33/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.4553 - acc: 0.2316 - val_loss: 2.2871 - val_acc: 0.2187\n",
            "Epoch 34/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.4447 - acc: 0.2329 - val_loss: 2.2856 - val_acc: 0.2195\n",
            "Epoch 35/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.4344 - acc: 0.2338 - val_loss: 2.2762 - val_acc: 0.2214\n",
            "Epoch 36/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.4246 - acc: 0.2349 - val_loss: 2.2690 - val_acc: 0.2226\n",
            "Epoch 37/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.4155 - acc: 0.2357 - val_loss: 2.2706 - val_acc: 0.2210\n",
            "Epoch 38/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.4059 - acc: 0.2369 - val_loss: 2.2644 - val_acc: 0.2226\n",
            "Epoch 39/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3963 - acc: 0.2379 - val_loss: 2.2564 - val_acc: 0.2222\n",
            "Epoch 40/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3874 - acc: 0.2396 - val_loss: 2.2609 - val_acc: 0.2240\n",
            "Epoch 41/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3781 - acc: 0.2404 - val_loss: 2.2468 - val_acc: 0.2261\n",
            "Epoch 42/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3692 - acc: 0.2416 - val_loss: 2.2476 - val_acc: 0.2265\n",
            "Epoch 43/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3601 - acc: 0.2435 - val_loss: 2.2395 - val_acc: 0.2305\n",
            "Epoch 44/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3510 - acc: 0.2443 - val_loss: 2.2343 - val_acc: 0.2315\n",
            "Epoch 45/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3421 - acc: 0.2459 - val_loss: 2.2295 - val_acc: 0.2310\n",
            "Epoch 46/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3340 - acc: 0.2476 - val_loss: 2.2255 - val_acc: 0.2313\n",
            "Epoch 47/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3253 - acc: 0.2492 - val_loss: 2.2242 - val_acc: 0.2316\n",
            "Epoch 48/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.3166 - acc: 0.2508 - val_loss: 2.2216 - val_acc: 0.2354\n",
            "Epoch 49/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3080 - acc: 0.2522 - val_loss: 2.2267 - val_acc: 0.2309\n",
            "Epoch 50/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.3005 - acc: 0.2533 - val_loss: 2.2160 - val_acc: 0.2364\n",
            "Epoch 51/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2919 - acc: 0.2548 - val_loss: 2.2267 - val_acc: 0.2328\n",
            "Epoch 52/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2847 - acc: 0.2557 - val_loss: 2.2119 - val_acc: 0.2356\n",
            "Epoch 53/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2766 - acc: 0.2567 - val_loss: 2.2179 - val_acc: 0.2366\n",
            "Epoch 54/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2689 - acc: 0.2579 - val_loss: 2.2072 - val_acc: 0.2381\n",
            "Epoch 55/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2618 - acc: 0.2590 - val_loss: 2.2048 - val_acc: 0.2408\n",
            "Epoch 56/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2548 - acc: 0.2605 - val_loss: 2.1990 - val_acc: 0.2354\n",
            "Epoch 57/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2479 - acc: 0.2622 - val_loss: 2.1996 - val_acc: 0.2386\n",
            "Epoch 58/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2401 - acc: 0.2622 - val_loss: 2.2044 - val_acc: 0.2384\n",
            "Epoch 59/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2343 - acc: 0.2632 - val_loss: 2.1949 - val_acc: 0.2411\n",
            "Epoch 60/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2283 - acc: 0.2641 - val_loss: 2.1911 - val_acc: 0.2414\n",
            "Epoch 61/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2210 - acc: 0.2651 - val_loss: 2.1928 - val_acc: 0.2396\n",
            "Epoch 62/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2150 - acc: 0.2663 - val_loss: 2.1844 - val_acc: 0.2415\n",
            "Epoch 63/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.2085 - acc: 0.2668 - val_loss: 2.1870 - val_acc: 0.2417\n",
            "Epoch 64/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.2025 - acc: 0.2680 - val_loss: 2.1873 - val_acc: 0.2399\n",
            "Epoch 65/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1970 - acc: 0.2681 - val_loss: 2.1881 - val_acc: 0.2423\n",
            "Epoch 66/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1905 - acc: 0.2690 - val_loss: 2.1913 - val_acc: 0.2401\n",
            "Epoch 67/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1851 - acc: 0.2700 - val_loss: 2.1866 - val_acc: 0.2424\n",
            "Epoch 68/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1792 - acc: 0.2704 - val_loss: 2.1828 - val_acc: 0.2427\n",
            "Epoch 69/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1734 - acc: 0.2714 - val_loss: 2.1811 - val_acc: 0.2421\n",
            "Epoch 70/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1679 - acc: 0.2725 - val_loss: 2.1816 - val_acc: 0.2430\n",
            "Epoch 71/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1621 - acc: 0.2728 - val_loss: 2.1834 - val_acc: 0.2445\n",
            "Epoch 72/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1579 - acc: 0.2738 - val_loss: 2.1762 - val_acc: 0.2437\n",
            "Epoch 73/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.1528 - acc: 0.2748 - val_loss: 2.1773 - val_acc: 0.2441\n",
            "Epoch 74/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1476 - acc: 0.2751 - val_loss: 2.1775 - val_acc: 0.2456\n",
            "Epoch 75/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1422 - acc: 0.2754 - val_loss: 2.1740 - val_acc: 0.2444\n",
            "Epoch 76/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1384 - acc: 0.2760 - val_loss: 2.1777 - val_acc: 0.2427\n",
            "Epoch 77/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.1326 - acc: 0.2772 - val_loss: 2.1809 - val_acc: 0.2444\n",
            "Epoch 78/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1282 - acc: 0.2777 - val_loss: 2.1751 - val_acc: 0.2442\n",
            "Epoch 79/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1238 - acc: 0.2787 - val_loss: 2.1717 - val_acc: 0.2455\n",
            "Epoch 80/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1189 - acc: 0.2793 - val_loss: 2.1791 - val_acc: 0.2467\n",
            "Epoch 81/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1141 - acc: 0.2796 - val_loss: 2.1709 - val_acc: 0.2466\n",
            "Epoch 82/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1099 - acc: 0.2803 - val_loss: 2.1793 - val_acc: 0.2451\n",
            "Epoch 83/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1056 - acc: 0.2814 - val_loss: 2.1798 - val_acc: 0.2453\n",
            "Epoch 84/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.1012 - acc: 0.2821 - val_loss: 2.1718 - val_acc: 0.2473\n",
            "Epoch 85/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0968 - acc: 0.2826 - val_loss: 2.1765 - val_acc: 0.2466\n",
            "Epoch 86/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0921 - acc: 0.2833 - val_loss: 2.1779 - val_acc: 0.2474\n",
            "Epoch 87/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.0887 - acc: 0.2836 - val_loss: 2.1786 - val_acc: 0.2461\n",
            "Epoch 88/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.0844 - acc: 0.2844 - val_loss: 2.1758 - val_acc: 0.2478\n",
            "Epoch 89/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0802 - acc: 0.2854 - val_loss: 2.1762 - val_acc: 0.2448\n",
            "Epoch 90/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0763 - acc: 0.2859 - val_loss: 2.1849 - val_acc: 0.2470\n",
            "Epoch 91/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0719 - acc: 0.2864 - val_loss: 2.1835 - val_acc: 0.2471\n",
            "Epoch 92/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.0685 - acc: 0.2870 - val_loss: 2.1799 - val_acc: 0.2486\n",
            "Epoch 93/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0644 - acc: 0.2876 - val_loss: 2.1783 - val_acc: 0.2481\n",
            "Epoch 94/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0609 - acc: 0.2878 - val_loss: 2.1816 - val_acc: 0.2503\n",
            "Epoch 95/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0566 - acc: 0.2890 - val_loss: 2.1887 - val_acc: 0.2486\n",
            "Epoch 96/100\n",
            "9000/9000 [==============================] - 22s 2ms/step - loss: 1.0529 - acc: 0.2890 - val_loss: 2.1845 - val_acc: 0.2453\n",
            "Epoch 97/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0498 - acc: 0.2896 - val_loss: 2.1822 - val_acc: 0.2475\n",
            "Epoch 98/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0459 - acc: 0.2902 - val_loss: 2.1832 - val_acc: 0.2467\n",
            "Epoch 99/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0428 - acc: 0.2902 - val_loss: 2.1869 - val_acc: 0.2475\n",
            "Epoch 100/100\n",
            "9000/9000 [==============================] - 21s 2ms/step - loss: 1.0389 - acc: 0.2909 - val_loss: 2.1909 - val_acc: 0.2471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff17fa12cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFpgZL8iyNv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "1a14ca22-2a79-459f-f5d3-50774aeb473b"
      },
      "source": [
        "encoder_model = models.Model(encoder_inputs, state_h)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 50)          119300    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  [(None, 50), (None, 50)]  15150     \n",
            "=================================================================\n",
            "Total params: 134,450\n",
            "Trainable params: 134,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe8BLBkgydKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
        "\n",
        "final_de_x2 = de_x(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2 = decoder_gru(final_de_x2, initial_state=decoder_state_input_h)\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "decoder_model = models.Model(\n",
        "    [decoder_inputs, decoder_state_input_h],\n",
        "    [decoder_outputs2, state_h2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG3TCjG4zIhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsBHEuoPzYh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h = decoder_model.predict([target_seq, states_value])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or len(decoded_sentence) > 52):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = h\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}